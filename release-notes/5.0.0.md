# 5.0.0

## ⚠ Breaking Changes

* Python versions 3.8 and 3.9 are no longer supported.
* `bcd` datasource has been removed.
* Two internal tables were added, `dipdup_contract_metadata` and `dipdup_token_metadata`.
* Some methods of `tzkt` datasource have changed their signatures and behavior.

## ⚠ Migration from 4.x

* Ensure that you have a `python = "^3.10"` dependency in `pyproject.toml`.
* Remove `bcd` datasources from config. Use `metadata` datasource instead to fetch contract and token metadata.
* Update `tzkt` datasource method calls as described below.
* Run the `dipdup schema approve` command on every database you use with 5.0.0.

## What's New

### BCD API takedown

Better Call Dev API has been officially deprecated in February. Thus, it's time to go for `bcd` datasource. In DipDup it served the only purpose of fetching contract and token metadata. Now there's a separate `metadata` datasource which do the same thing, but better. If you have used `bcd` datasource for custom requests see [How to migrate from BCD to TzKT API](https://baking-bad.org/blog/2022/02/15/migrating-from-bcd-api-to-tzkt-api/) article.

### TzKT batch request pagination

Historically, most of `TzktDatasource` methods had a page iteration logic hidden inside. Number of items returned by TzKT in a single request configured in `HTTPConfig.batch_size` and defaults to 10.000. Let's say you need to fetch 25.000 big map keys with `get_big_map` methods. Before this release three requests would be performed under the hood. Over time it became clear that this approach leads to performance degradation and extensive memory usage.

| affected method | response size in 4.x | response size in 5.x |
|-|-|-|
| `get_similar_contracts` | unlimited | max. `datasource.request_limit` |
| `get_originated_contracts` | unlimited | max. `datasource.request_limit` |
| `get_big_map` | unlimited | max. `datasource.request_limit` |
| `get_contract_big_maps` | unlimited | max. `datasource.request_limit` |
| `get_quotes` | first `datasource.request_limit` | max. `datasource.request_limit` |

```python
datasource = ctx.get_tzkt_datasource('tzkt_mainnet')
batch_iter = datasource.iter_big_map(
    big_map_id=big_map_id,
    level=last_level,
)
async for key_batch in batch_iter:
    for key in key_batch:
        ...
```
