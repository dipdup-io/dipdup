# 5.0.0

## ⚠ Breaking Changes

* Python versions 3.8 and 3.9 are no longer supported.
* `bcd` datasource has been removed.
* Two internal tables were added, `dipdup_contract_metadata` and `dipdup_token_metadata`.
* Some methods of `tzkt` datasource have changed their signatures and behavior.
* `advanced.oneshot` config flag has been removed.
* `docker init` command has been removed.
* `ReindexingReason` enumeration items have been changed.

## ⚠ Migration from 4.x

* Ensure that you have a `python = "^3.10"` dependency in `pyproject.toml`.
* Remove `bcd` datasources from config. Use `metadata` datasource instead to fetch contract and token metadata.
* Update `tzkt` datasource method calls as described below.
* Run the `dipdup schema approve` command on every database you use with 5.0.0.
* Update usage of `ReindexingReason` enumeration if needed.

## What's New

### BCD API takedown

Better Call Dev API was officially deprecated in February. Thus, it's time to go for `bcd` datasource. In DipDup, it served the only purpose of fetching contract and token metadata. Now there's a separate `metadata` datasource which do the same thing, but better. In case you have used `bcd` datasource for custom requests, see [How to migrate from BCD to TzKT API](https://baking-bad.org/blog/2022/02/15/migrating-from-bcd-api-to-tzkt-api/) article.

### TzKT batch request pagination

Historically, most `TzktDatasource` methods had a page iteration logic hidden inside. A number of items returned by TzKT in a single request configured in `HTTPConfig.batch_size` and defaults to 10.000. Let's say you need to fetch 25.000 big map keys with `get_big_map` method. Before this release, three requests would be performed under the hood. Over time it became clear that this approach leads to performance degradation and extensive memory usage. 

| affected method | response size in 4.x | response size in 5.x |
|-|-|-|
| `get_similar_contracts` | unlimited | max. `datasource.request_limit` |
| `get_originated_contracts` | unlimited | max. `datasource.request_limit` |
| `get_big_map` | unlimited | max. `datasource.request_limit` |
| `get_contract_big_maps` | unlimited | max. `datasource.request_limit` |
| `get_quotes` | first `datasource.request_limit` | max. `datasource.request_limit` |

```python
datasource = ctx.get_tzkt_datasource('tzkt_mainnet')
batch_iter = datasource.iter_big_map(
    big_map_id=big_map_id,
    level=last_level,
)
async for key_batch in batch_iter:
    for key in key_batch:
        ...
```

### Metadata interface for TzKT integration

`update_contract_metadata`

`update_token_metadata`

### Generic `http` datasource


### Prometheus integration

This version introduces initial Prometheus integration. It could help you to set up monitoring, find pefrormance issues in your code, and so on. To enable this integration add the following lines to config:

```yaml
prometheus:
  host: 0.0.0.0
```

The following metrics will be exposed:

| metric name | description |
|-|-|
| `dipdup_indexes_total` | Number of indexes in operation by status |
| `dipdup_index_level_sync_duration_seconds` | Duration of indexing a single level |
| `dipdup_index_level_realtime_duration_seconds` | Duration of last index syncronization |
| `dipdup_index_total_sync_duration_seconds` | Duration of the last index syncronization |
| `dipdup_index_total_realtime_duration_seconds` | Duration of the last index realtime syncronization |
| `dipdup_index_levels_to_sync_total` | Number of levels to reach synced state |
| `dipdup_index_levels_to_realtime_total` | Number of levels to reach realtime state |
| `dipdup_index_handlers_matched_total` | Index total hits |
| `dipdup_datasource_head_updated_timestamp` | Timestamp of the last head update |
| `dipdup_datasource_rollbacks_total` | Number of rollbacks |
| `dipdup_http_errors_total` | Number of http errors |
| `dipdup_callback_duration_seconds` | Duration of callback execution |




## Changes singe 4.2.6